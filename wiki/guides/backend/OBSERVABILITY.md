# Observability & Debug

Guide pour d√©boguer le pipeline et monitorer la performance.

## üìã Table des mati√®res

1. [Headers de r√©ponse](#headers-de-r√©ponse)
2. [DevTools Network inspection](#devtools-network-inspection)
3. [Logs Pino structur√©s](#logs-pino-structur√©s)
4. [Tracing et correlation ID](#tracing-et-correlation-id)
5. [Monitoring et alertes](#monitoring-et-alertes)

---

## üìä Headers de r√©ponse

### Server-Timing

```http
Server-Timing: fetchObs;dur=150, buildIndex;dur=45, pickTarget;dur=12, buildLures;dur=78, taxa;dur=120, labels;dur=25, total;dur=430
```

**Format** : `label;dur=milliseconds`

| Label | D√©tail |
|-------|--------|
| `fetchObs` | Fetch observations depuis iNat (paginated) |
| `buildIndex` | Index par taxon (cr√©ation byTaxon + taxonList) |
| `pickTarget` | S√©lection taxon cible (LCA, anti-cooldown) |
| `buildLures` | G√©n√©ration leurres (LCA bucketing) |
| `taxa` | Fetch d√©tails taxa (Wikipedia, common names) |
| `labels` | Construire labels uniques + shuffle |
| `total` | Temps total du pipeline |

**Interpr√©tation** :
- `total` > 1000ms ? Pipeline lent, check fetchObs ou taxa
- `fetchObs` > 500ms ? iNat API lente ou r√©seau
- `buildLures` > 100ms ? Pool grand, LCA calcul lourd

### X-Cache-Key

```http
X-Cache-Key: geo=place_7953|month=10,11,12|version=1705340400000
```

Cl√© utilis√©e pour lookup questionCache. Utile pour v√©rifier :
- Normalisation g√©o correcte ?
- P√©riode normalis√©e OK ?
- Cache hit/miss pour debug

### X-Selection-Geo

```http
X-Selection-Geo: place_id
```

Mode g√©o choisi : `place_id`, `bbox`, ou `global`.

**V√©rifier** :
- Si utilisateur a sp√©cifi√© place_id, doit √™tre `place_id`
- Si bbox invalide, fallback `global` ?

### X-Lure-Buckets

```http
X-Lure-Buckets: near=2, mid=1, far=1
```

Distribution LCA buckets pour leurres.

**Interpr√©tation** :
- `near=0` ? Pas d'observations proches taxonomiquement (√©tonnant)
- `mid=0, far=0` ? Peu de diversit√© (am√©liorer pool)
- Id√©al : `near=1-2, mid=1-2, far=1` (m√©lange)

### X-Pool-*

```http
X-Pool-Pages: 5
X-Pool-Obs: 400
X-Pool-Taxa: 87
```

Donn√©es iNat charg√©es :
- `X-Pool-Pages` : Nombre de pages iNat fetched
- `X-Pool-Obs` : Total observations dans pool
- `X-Pool-Taxa` : Taxa distincts

**Diagnostic** :
- `X-Pool-Taxa` < 10 ? Place peu d'observations, filtres trop stricts
- `X-Pool-Pages` = MAX ? Peut augmenter MAX_OBS_PAGES

### X-Lures-Relaxed

```http
X-Lures-Relaxed: false
```

Bool√©en : fallback relaxed activation ? (pool √©puis√©, cooldown strict)

- `false` : S√©lection normale, OK
- `true` : Deck/cooldown √©puis√©, utilis√© fallback pond√©r√©

### X-Request-Id

```http
X-Request-Id: req-abc123xyz789
```

ID unique pour chaque requ√™te. Tracing dans logs.

### X-RateLimit-*

```http
X-RateLimit-Limit: 100
X-RateLimit-Remaining: 98
X-RateLimit-Reset: 1705340460
```

Rate limiting par IP (iNat + middleware).

---

## üîç DevTools Network inspection

### Ouvrir DevTools

1. Ouvrir Firefox/Chrome DevTools (`F12`)
2. Aller √† onglet **Network**
3. Recharger page (`Cmd+R`)
4. Cliquer requ√™te `quiz-question`

### Voir les headers

1. Cliquer requ√™te
2. Onglet **Response Headers**
3. Chercher `Server-Timing`, `X-Cache-Key`, etc.

### Visualiser Server-Timing

1. Onglet **Timings** (Firefox) ou **Timing** (Chrome)
2. Voir graph timing par √©tape

### Calculer latency

```
Response time (DevTools)
= Network latency + Server processing + Browser parsing

Server-Timing (header)
= Server processing only

Network latency
= Response time - Server-Timing total
```

### Exemple analysis

```
Total latency: 800ms
‚îú‚îÄ Network: 200ms (client IP loin, latency r√©seau)
‚îú‚îÄ Server: 430ms (Server-Timing)
‚îÇ  ‚îú‚îÄ fetchObs: 150ms (iNat lent)
‚îÇ  ‚îú‚îÄ buildIndex: 45ms
‚îÇ  ‚îú‚îÄ pickTarget: 12ms
‚îÇ  ‚îú‚îÄ buildLures: 78ms (LCA calcul)
‚îÇ  ‚îú‚îÄ taxa: 120ms (fetching Wikipedia)
‚îÇ  ‚îî‚îÄ labels: 25ms
‚îî‚îÄ Browser: 170ms (parsing JSON, render)

Action: Taxa detail fetch est lent (120ms).
        V√©rifier si iNat API locale est charg√©e.
```

---

## üìù Logs Pino structur√©s

### Format JSON

Tous les logs Pino sont JSON pour parsing automatique.

```bash
npm run dev 2>&1 | head -50
```

Exemple log:

```json
{
  "level": 30,
  "time": 1705340400123,
  "pid": 12345,
  "hostname": "macbook-pro",
  "msg": "GET /api/quiz-question",
  "req": {
    "id": "req-abc123",
    "method": "GET",
    "url": "/api/quiz-question?pack=mushrooms&locale=en",
    "remoteAddress": "127.0.0.1",
    "remotePort": 54321
  },
  "res": {
    "statusCode": 200,
    "contentLength": 8234
  },
  "responseTime": 430,
  "quiz": {
    "pack": "mushrooms",
    "locale": "en",
    "cacheKey": "geo=...",
    "cacheHit": false,
    "targetTaxonId": 52367,
    "lureCount": 4
  },
  "cache": {
    "questionCacheSize": 12,
    "selectionStateCacheSize": 8,
    "hit": false,
    "revalidated": false
  },
  "timing": {
    "fetchObs": 150,
    "buildIndex": 45,
    "pickTarget": 12,
    "buildLures": 78,
    "taxa": 120,
    "labels": 25,
    "total": 430
  },
  "lures": {
    "buckets": { "near": 2, "mid": 1, "far": 1 },
    "relaxed": false
  },
  "pool": {
    "pages": 5,
    "obs": 400,
    "taxa": 87
  }
}
```

### Filtering logs

```bash
# Voir seulement quiz-question requests
npm run dev 2>&1 | jq 'select(.msg | contains("quiz-question"))'

# Voir requ√™tes lentes (> 500ms)
npm run dev 2>&1 | jq 'select(.responseTime > 500)'

# Voir erreurs
npm run dev 2>&1 | jq 'select(.level >= 40)'  # warn=40, error=50, fatal=60

# Voir cache hits
npm run dev 2>&1 | jq 'select(.cache.hit == true)'

# Timeline per taxon
npm run dev 2>&1 | jq '.quiz.targetTaxonId' | sort | uniq -c
```

### Log levels

| Level | Value | Usage |
|-------|-------|-------|
| trace | 10 | Tr√®s verbose, ne pas en prod |
| debug | 20 | Infos debug (cache lookup, normalization) |
| info | 30 | √âv√®nements normaux (requests, responses) |
| warn | 40 | Probl√®mes non-critiques (pool petit, fallback) |
| error | 50 | Erreurs (API fail, validation error) |
| fatal | 60 | Critique (crash imminent) |

---

## üîó Tracing et correlation ID

### X-Request-Id

Chaque requ√™te re√ßoit unique ID pour tracer √† travers logs:

```javascript
// server.js
app.use(pinoHttp({
  genReqId: () => `req-${generateId()}`,
}));

// Dans handler
app.get('/api/quiz-question', (req, res) => {
  const requestId = req.id;  // "req-abc123"
  logger.info({ requestId, msg: 'Processing quiz request' });
  // ...
});
```

### Tracing exemple

Request arrives:
```
2025-01-15T10:30:00.123Z [req-abc123] GET /api/quiz-question?pack=mushrooms
2025-01-15T10:30:00.273Z [req-abc123] Cache miss, fetching observations
2025-01-15T10:30:00.429Z [req-abc123] Building index (87 taxa)
2025-01-15T10:30:00.553Z [req-abc123] Response 200 OK, 430ms
```

Chercher dans logs: `grep "req-abc123"`

---

## üìà Monitoring et alertes

### Prometheus metrics (futur)

```javascript
// Exemple: Exposer m√©triques pour Prometheus scraping

const prom = require('prom-client');

// Metrics
const requestDuration = new prom.Histogram({
  name: 'quiz_request_duration_ms',
  help: 'Quiz request duration in milliseconds',
  buckets: [100, 250, 500, 1000, 2000, 5000],
  labelNames: ['cache_hit'],
});

const cacheHitRate = new prom.Gauge({
  name: 'quiz_cache_hit_rate',
  help: 'Cache hit rate (0-1)',
});

const poolSize = new prom.Gauge({
  name: 'quiz_pool_size',
  help: 'Current observation pool size',
  labelNames: ['pack'],
});

// Usage
const timer = requestDuration.startTimer();
// ... process request ...
timer({ cache_hit: cacheHit });

// Expose endpoint
app.get('/metrics', (req, res) => {
  res.set('Content-Type', prom.register.contentType);
  res.end(prom.register.metrics());
});
```

### Key metrics to monitor

| Metric | Target | Alert |
|--------|--------|-------|
| Request latency (p99) | < 1000ms | > 2000ms |
| Cache hit rate | > 70% | < 50% |
| iNat API error rate | < 1% | > 5% |
| Pool taxa count | > 50 | < 10 |
| Lure diversity (far bucket) | > 0 | = 0 |

### Alerting rules (Prometheus)

```yaml
groups:
  - name: inaturamouche
    rules:
      - alert: QuizLatencySlow
        expr: histogram_quantile(0.99, quiz_request_duration_ms) > 2000
        for: 5m
        annotations:
          summary: "Quiz endpoint p99 latency > 2s"

      - alert: CacheHitRateLow
        expr: quiz_cache_hit_rate < 0.5
        for: 10m
        annotations:
          summary: "Cache hit rate < 50%"

      - alert: iNatApiErrors
        expr: rate(inaturalist_api_errors[5m]) > 0.05
        for: 5m
        annotations:
          summary: "iNat API error rate > 5%"
```

### Dashboard Grafana

Example queries:

```
# Average latency by cache hit
avg(quiz_request_duration_ms) by (cache_hit)

# Cache hit rate over time
quiz_cache_hit_rate

# Request rate
rate(quiz_requests_total[1m])

# Pool size distribution
histogram_quantile(0.95, quiz_pool_size)
```

---

## üéØ Common debugging scenarios

### Sc√©nario 1: Requ√™te lente (> 1000ms)

```
Checklist:
1. V√©rifier Server-Timing (quelle √©tape est lente ?)
2. Si fetchObs lent (> 300ms)
   ‚Üí iNat API lente ou r√©seau mauvais
   ‚Üí V√©rifier X-Pool-Pages (combien fetched ?)
   ‚Üí Possiblement augmenter MAX_OBS_PAGES ?
3. Si taxa lent (> 200ms)
   ‚Üí Fetch Wikipedia lent
   ‚Üí V√©rifier taxonDetailsCache hit rate
   ‚Üí Possibly pre-warm cache
4. Si buildLures lent (> 150ms)
   ‚Üí Beaucoup d'observations, LCA calcul lourd
   ‚Üí Optimiser calcul ou cache LCA
```

### Sc√©nario 2: Pool petit (< 20 taxa)

```
Checklist:
1. V√©rifier X-Pool-Taxa header
2. V√©rifier X-Pool-Obs (combien observations total ?)
3. Filtres trop stricts ?
   ‚Üí place_id + taxon_ids + p√©riode ?
   ‚Üí Tester sans filtres pour verifier
4. iNat API retourne peu d'observations ?
   ‚Üí V√©rifier X-Pool-Pages (fetching enough ?)
   ‚Üí V√©rifier param√®tres GET iNat (correct format ?)
5. Donn√©es iNat anciennes pour cette place
```

### Sc√©nario 3: Pas de leurres near (X-Lure-Buckets: near=0)

```
Checklist:
1. Pool trop petit ? (besoin diversity)
2. Filtre period bloque observations proches ?
3. LCA bucketing broken ?
   ‚Üí Verifier ancestors data dans observations
   ‚Üí Test buildLures algo ind√©pendemment
4. Possible solution : √©largir filtres
```

### Sc√©nario 4: Cache miss fr√©quent

```
Checklist:
1. V√©rifier X-Cache-Key (correct ?)
2. Utilisateurs utilisent diff√©rents filtres chaque fois ?
   ‚Üí Cache fragmentation (peu r√©utilisation)
3. TTL trop court ? (expiry rapide)
4. Cache size trop petit ? (eviction)
   ‚Üí V√©rifier questionCache size dans logs
5. V√©rifier cache revalidation en BG (SWR)
   ‚Üí Log "revalidated": true ?
```

---

## üìö Ressources

- [ARCHITECTURE.md](../ARCHITECTURE.md) ‚Äì Vue d'ensemble + Server-Timing diagram
- [CACHE_STRATEGY.md](./CACHE_STRATEGY.md) ‚Äì Cache internals
- [QUIZ_PIPELINE.md](./QUIZ_PIPELINE.md) ‚Äì Algorithmes d√©tail
